{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=wQ8BIBpya2k\n",
    "# pip install h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import cv2\n",
    "import h5py\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# NAME = \"Num_LeNet-{}\".format(int(time.time()))\n",
    "# tensorboard = TensorBoard(log_dir = 'logs/{}'.format(NAME))\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.9)\n",
    "config=tf.ConfigProto(gpu_options=gpu_options)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "\n",
    "\n",
    "pickle_in = open(\"num_mat_train_bin.pickle\", \"rb\")\n",
    "x_train_mat = pickle.load(pickle_in)\n",
    "# x_train_mat = tf.keras.utils.normalize(x_train_mat, axis=2)\n",
    "# for i in range(0, len(x_train_mat)):\n",
    "#     ret, x_train_mat[i] = cv2.threshold(x_train_mat[i],20,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    \n",
    "# cv2.imshow('test', x_train_mat[1])\n",
    "# key_in = cv2.waitKey(0) & 0xFF\n",
    "# if key_in == 27:    # esc\n",
    "#     cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "pickle_in = open(\"num_y_train.pickle\", \"rb\")\n",
    "y_train_mat = pickle.load(pickle_in)\n",
    "# y_train_mat = np_utils.to_categorical(y_train_mat, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [1, 2]\n",
    "layer_sizes = [64, 128]\n",
    "conv_layers = [1]\n",
    "epoch_time = 20\n",
    "drop_rate = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_LeNet-1-conv-64-nodes-1-dense-7.0-drop-20-epo-1570321023\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                692288    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 693,834\n",
      "Trainable params: 693,706\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 33s 613us/step - loss: 1.2125 - acc: 0.5667 - val_loss: 0.3928 - val_acc: 0.9028\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 33s 608us/step - loss: 0.9816 - acc: 0.6587 - val_loss: 0.2997 - val_acc: 0.9235\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 33s 608us/step - loss: 0.9342 - acc: 0.6801 - val_loss: 0.2877 - val_acc: 0.9220\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 33s 609us/step - loss: 0.9076 - acc: 0.6837 - val_loss: 0.2602 - val_acc: 0.9268\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 33s 609us/step - loss: 0.8752 - acc: 0.6979 - val_loss: 0.2703 - val_acc: 0.9293\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 33s 608us/step - loss: 0.8449 - acc: 0.7091 - val_loss: 0.2393 - val_acc: 0.9365\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 33s 608us/step - loss: 0.8219 - acc: 0.7179 - val_loss: 0.2400 - val_acc: 0.9318\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 33s 609us/step - loss: 0.8068 - acc: 0.7218 - val_loss: 0.2356 - val_acc: 0.9338\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 33s 608us/step - loss: 0.7869 - acc: 0.7276 - val_loss: 0.2296 - val_acc: 0.9378\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 33s 608us/step - loss: 0.7746 - acc: 0.7302 - val_loss: 0.2440 - val_acc: 0.9378\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 33s 605us/step - loss: 0.7662 - acc: 0.7352 - val_loss: 0.2217 - val_acc: 0.9372\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 33s 608us/step - loss: 0.7487 - acc: 0.7386 - val_loss: 0.2233 - val_acc: 0.9395\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 33s 607us/step - loss: 0.7497 - acc: 0.7386 - val_loss: 0.2176 - val_acc: 0.9400\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 33s 607us/step - loss: 0.7418 - acc: 0.7423 - val_loss: 0.2146 - val_acc: 0.9433\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 33s 607us/step - loss: 0.7301 - acc: 0.7475 - val_loss: 0.2192 - val_acc: 0.9405\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 33s 609us/step - loss: 0.7280 - acc: 0.7498 - val_loss: 0.2213 - val_acc: 0.9397\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 33s 608us/step - loss: 0.7048 - acc: 0.7591 - val_loss: 0.2205 - val_acc: 0.9427\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 33s 609us/step - loss: 0.7061 - acc: 0.7606 - val_loss: 0.2070 - val_acc: 0.9427\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 33s 611us/step - loss: 0.6909 - acc: 0.7629 - val_loss: 0.1993 - val_acc: 0.9442\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 33s 609us/step - loss: 0.6898 - acc: 0.7638 - val_loss: 0.2051 - val_acc: 0.9452\n",
      "Num_LeNet-1-conv-128-nodes-1-dense-7.0-drop-20-epo-1570321682\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               1384576   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,386,762\n",
      "Trainable params: 1,386,634\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 46s 847us/step - loss: 0.7863 - acc: 0.7468 - val_loss: 0.2480 - val_acc: 0.9278\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 45s 842us/step - loss: 0.6164 - acc: 0.8087 - val_loss: 0.2079 - val_acc: 0.9398\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 45s 841us/step - loss: 0.5752 - acc: 0.8215 - val_loss: 0.1999 - val_acc: 0.9438\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 45s 841us/step - loss: 0.5448 - acc: 0.8298 - val_loss: 0.1871 - val_acc: 0.9463\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 45s 841us/step - loss: 0.5242 - acc: 0.8379 - val_loss: 0.1753 - val_acc: 0.9503\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 45s 842us/step - loss: 0.4991 - acc: 0.8440 - val_loss: 0.1686 - val_acc: 0.9530\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 46s 844us/step - loss: 0.4902 - acc: 0.8491 - val_loss: 0.1617 - val_acc: 0.9537\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 45s 842us/step - loss: 0.4751 - acc: 0.8515 - val_loss: 0.1590 - val_acc: 0.9528\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 45s 842us/step - loss: 0.4655 - acc: 0.8562 - val_loss: 0.1541 - val_acc: 0.9575\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 45s 841us/step - loss: 0.4547 - acc: 0.8591 - val_loss: 0.1549 - val_acc: 0.9558\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 45s 842us/step - loss: 0.4419 - acc: 0.8623 - val_loss: 0.1448 - val_acc: 0.9568\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 46s 843us/step - loss: 0.4329 - acc: 0.8641 - val_loss: 0.1442 - val_acc: 0.9572\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 45s 842us/step - loss: 0.4281 - acc: 0.8688 - val_loss: 0.1441 - val_acc: 0.9587\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 45s 841us/step - loss: 0.4179 - acc: 0.8696 - val_loss: 0.1457 - val_acc: 0.9568\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 45s 842us/step - loss: 0.4120 - acc: 0.8722 - val_loss: 0.1483 - val_acc: 0.9608\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 45s 842us/step - loss: 0.4037 - acc: 0.8751 - val_loss: 0.1352 - val_acc: 0.9620\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 46s 844us/step - loss: 0.4018 - acc: 0.8738 - val_loss: 0.1373 - val_acc: 0.9610\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 45s 842us/step - loss: 0.3917 - acc: 0.8764 - val_loss: 0.1334 - val_acc: 0.9632\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 45s 841us/step - loss: 0.3819 - acc: 0.8791 - val_loss: 0.1366 - val_acc: 0.9620\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000/54000 [==============================] - 45s 842us/step - loss: 0.3762 - acc: 0.8810 - val_loss: 0.1364 - val_acc: 0.9610\n",
      "Num_LeNet-1-conv-64-nodes-2-dense-7.0-drop-20-epo-1570322593\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                692288    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 697,994\n",
      "Trainable params: 697,866\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 34s 631us/step - loss: 2.2567 - acc: 0.1287 - val_loss: 2.0263 - val_acc: 0.2830\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 34s 622us/step - loss: 2.1909 - acc: 0.1611 - val_loss: 1.9241 - val_acc: 0.3027\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 34s 622us/step - loss: 2.1680 - acc: 0.1704 - val_loss: 1.9251 - val_acc: 0.2988\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 34s 625us/step - loss: 2.1618 - acc: 0.1707 - val_loss: 1.8798 - val_acc: 0.3025\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 34s 624us/step - loss: 2.1603 - acc: 0.1700 - val_loss: 1.9128 - val_acc: 0.2932\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 34s 623us/step - loss: 2.1551 - acc: 0.1734 - val_loss: 1.8975 - val_acc: 0.2977\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 34s 622us/step - loss: 2.1505 - acc: 0.1733 - val_loss: 1.8829 - val_acc: 0.3078\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 34s 623us/step - loss: 2.1434 - acc: 0.1754 - val_loss: 1.8314 - val_acc: 0.3292\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 34s 623us/step - loss: 2.1333 - acc: 0.1779 - val_loss: 1.8497 - val_acc: 0.3437\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 34s 621us/step - loss: 2.1307 - acc: 0.1768 - val_loss: 1.7880 - val_acc: 0.3620\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 34s 624us/step - loss: 2.1289 - acc: 0.1779 - val_loss: 1.8300 - val_acc: 0.3348\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 34s 623us/step - loss: 2.1231 - acc: 0.1794 - val_loss: 1.7857 - val_acc: 0.3430\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 34s 623us/step - loss: 2.1125 - acc: 0.1814 - val_loss: 1.7856 - val_acc: 0.3620\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 34s 624us/step - loss: 2.1087 - acc: 0.1843 - val_loss: 1.8538 - val_acc: 0.3467\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 34s 623us/step - loss: 2.1004 - acc: 0.1860 - val_loss: 1.7547 - val_acc: 0.3767\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 34s 622us/step - loss: 2.0978 - acc: 0.1888 - val_loss: 1.7621 - val_acc: 0.3790\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 34s 624us/step - loss: 2.0947 - acc: 0.1902 - val_loss: 1.7666 - val_acc: 0.3658\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 34s 622us/step - loss: 2.0965 - acc: 0.1890 - val_loss: 1.7487 - val_acc: 0.3760\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 34s 622us/step - loss: 2.0888 - acc: 0.1935 - val_loss: 1.8034 - val_acc: 0.3582\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 34s 623us/step - loss: 2.0894 - acc: 0.1938 - val_loss: 1.8156 - val_acc: 0.3587\n",
      "Num_LeNet-1-conv-128-nodes-2-dense-7.0-drop-20-epo-1570323268\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               1384576   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,403,274\n",
      "Trainable params: 1,403,146\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 47s 865us/step - loss: 1.9597 - acc: 0.2949 - val_loss: 1.2421 - val_acc: 0.6712\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 46s 858us/step - loss: 1.6696 - acc: 0.4053 - val_loss: 1.0457 - val_acc: 0.6928\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 46s 860us/step - loss: 1.5663 - acc: 0.4356 - val_loss: 0.9368 - val_acc: 0.7370\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 46s 858us/step - loss: 1.5355 - acc: 0.4386 - val_loss: 0.9574 - val_acc: 0.7258\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 46s 858us/step - loss: 1.4924 - acc: 0.4586 - val_loss: 0.8836 - val_acc: 0.7215\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 46s 859us/step - loss: 1.4634 - acc: 0.4697 - val_loss: 0.8810 - val_acc: 0.7422\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 46s 859us/step - loss: 1.4527 - acc: 0.4701 - val_loss: 0.8650 - val_acc: 0.7418\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 46s 859us/step - loss: 1.4384 - acc: 0.4732 - val_loss: 0.8734 - val_acc: 0.7348\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 46s 858us/step - loss: 1.4199 - acc: 0.4773 - val_loss: 0.8626 - val_acc: 0.7348\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 46s 859us/step - loss: 1.3906 - acc: 0.4899 - val_loss: 0.8828 - val_acc: 0.7257\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 46s 860us/step - loss: 1.3704 - acc: 0.4986 - val_loss: 0.8800 - val_acc: 0.7258\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 46s 860us/step - loss: 1.3591 - acc: 0.5009 - val_loss: 0.8757 - val_acc: 0.7242\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 46s 861us/step - loss: 1.3401 - acc: 0.5038 - val_loss: 0.8644 - val_acc: 0.7287\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 46s 858us/step - loss: 1.3427 - acc: 0.5014 - val_loss: 0.8537 - val_acc: 0.7168\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000/54000 [==============================] - 46s 859us/step - loss: 1.3297 - acc: 0.5060 - val_loss: 0.8227 - val_acc: 0.7665\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 46s 859us/step - loss: 1.3170 - acc: 0.5130 - val_loss: 0.8032 - val_acc: 0.7938\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 47s 862us/step - loss: 1.3091 - acc: 0.5186 - val_loss: 0.7952 - val_acc: 0.7805\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 46s 860us/step - loss: 1.3111 - acc: 0.5220 - val_loss: 0.7947 - val_acc: 0.7823\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 46s 861us/step - loss: 1.3021 - acc: 0.5216 - val_loss: 0.7936 - val_acc: 0.7743\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 46s 859us/step - loss: 1.2950 - acc: 0.5263 - val_loss: 0.8192 - val_acc: 0.7752\n"
     ]
    }
   ],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = f\"Num_LeNet-{conv_layer}-conv-{layer_size}-nodes-{dense_layer}-dense-{drop_rate*10}-drop-{epoch_time}-epo-{int(time.time())}\"\n",
    "            print(NAME)\n",
    "            tensorboard = TensorBoard(log_dir = 'logs/{}'.format(NAME))\n",
    "            \n",
    "            \n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=(28,28,1),padding='valid',activation='relu',kernel_initializer='uniform'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(64,(3,3),strides=(1,1),padding='valid',activation='relu',kernel_initializer='uniform'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "            \n",
    "            model.add(Flatten())\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation='relu'))\n",
    "                model.add(Dropout(0.7))\n",
    "                \n",
    "            model.add(Dense(10,activation='softmax'))\n",
    "            model.compile(optimizer=Adam(lr=0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "            model.summary()\n",
    "\n",
    "            # ————————————————\n",
    "            # 版权声明：本文为CSDN博主「wmy199216」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。\n",
    "            # 原文链接：https://blog.csdn.net/wmy199216/article/details/71171401\n",
    "\n",
    "            model.fit(x_train_mat, y_train_mat, epochs=epoch_time, validation_split=0.1, callbacks=[tensorboard])\n",
    "            model.save(NAME + \".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               102500    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 155,990\n",
      "Trainable params: 155,798\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 28s 519us/step - loss: 0.7842 - acc: 0.7494 - val_loss: 0.4873 - val_acc: 0.8507\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 27s 503us/step - loss: 0.4369 - acc: 0.8633 - val_loss: 0.3051 - val_acc: 0.9050\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 27s 506us/step - loss: 0.3123 - acc: 0.9032 - val_loss: 0.2186 - val_acc: 0.9348\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 27s 498us/step - loss: 0.2500 - acc: 0.9231 - val_loss: 0.1770 - val_acc: 0.9498\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 27s 498us/step - loss: 0.2113 - acc: 0.9343 - val_loss: 0.1646 - val_acc: 0.9523\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 27s 497us/step - loss: 0.1851 - acc: 0.9431 - val_loss: 0.1343 - val_acc: 0.9625\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 27s 497us/step - loss: 0.1675 - acc: 0.9483 - val_loss: 0.1306 - val_acc: 0.9610\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 27s 501us/step - loss: 0.1518 - acc: 0.9536 - val_loss: 0.1176 - val_acc: 0.9663\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 27s 496us/step - loss: 0.1411 - acc: 0.9566 - val_loss: 0.1192 - val_acc: 0.9673\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 27s 503us/step - loss: 0.1299 - acc: 0.9603 - val_loss: 0.1128 - val_acc: 0.9682\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(32,(5,5),strides=(1,1),input_shape=(28,28,1),padding='valid',activation='relu',kernel_initializer='uniform'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv2D(64,(5,5),strides=(1,1),padding='valid',activation='relu',kernel_initializer='uniform'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Flatten(input_shape=(4, 4, 64)))\n",
    "# model.add(Dense(100,activation='relu'))\n",
    "# model.add(Dense(10,activation='softmax'))\n",
    "# model.compile(optimizer=Adam(lr=0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "# # ————————————————\n",
    "# # 版权声明：本文为CSDN博主「wmy199216」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。\n",
    "# # 原文链接：https://blog.csdn.net/wmy199216/article/details/71171401\n",
    "\n",
    "# model.fit(x_train_mat, y_train_mat, epochs=10, validation_split=0.1, callbacks=[tensorboard])\n",
    "# model.save('epic_num_LeNet.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "## test load code\n",
    "\n",
    "# IMG_SIZE = 256\n",
    "# index = 0\n",
    "\n",
    "# resize_img = cv2.resize(x_train_mat[index], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "# print(y_train_mat[index])\n",
    "# cv2.imshow('test', resize_img)\n",
    "\n",
    "# key_in = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "# if key_in == 27:    # esc\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
