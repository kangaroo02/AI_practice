{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=wQ8BIBpya2k\n",
    "# pip install h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import cv2\n",
    "import h5py\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# NAME = \"Num_LeNet-{}\".format(int(time.time()))\n",
    "# tensorboard = TensorBoard(log_dir = 'logs/{}'.format(NAME))\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.9)\n",
    "config=tf.ConfigProto(gpu_options=gpu_options)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "\n",
    "\n",
    "pickle_in = open(\"num_mat_train_bin.pickle\", \"rb\")\n",
    "x_train_mat = pickle.load(pickle_in)\n",
    "# x_train_mat = tf.keras.utils.normalize(x_train_mat, axis=2)\n",
    "# for i in range(0, len(x_train_mat)):\n",
    "#     ret, x_train_mat[i] = cv2.threshold(x_train_mat[i],20,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    \n",
    "# cv2.imshow('test', x_train_mat[1])\n",
    "# key_in = cv2.waitKey(0) & 0xFF\n",
    "# if key_in == 27:    # esc\n",
    "#     cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "pickle_in = open(\"num_y_train.pickle\", \"rb\")\n",
    "y_train_mat = pickle.load(pickle_in)\n",
    "# y_train_mat = np_utils.to_categorical(y_train_mat, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [1, 2]\n",
    "layer_sizes = [64, 128]\n",
    "conv_layers = [1]\n",
    "epoch_time = 20\n",
    "drop_rate = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_LeNet-1-conv-64-nodes-1-dense-drop-20-epo-7.0-drop-1570288948\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                692288    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 693,834\n",
      "Trainable params: 693,706\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 33s 607us/step - loss: 1.1043 - acc: 0.6074 - val_loss: 0.3532 - val_acc: 0.9057\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 33s 606us/step - loss: 0.8948 - acc: 0.6879 - val_loss: 0.2681 - val_acc: 0.9245\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 33s 606us/step - loss: 0.8468 - acc: 0.7035 - val_loss: 0.2584 - val_acc: 0.9248\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 33s 604us/step - loss: 0.8220 - acc: 0.7129 - val_loss: 0.2895 - val_acc: 0.9238\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 33s 606us/step - loss: 0.7983 - acc: 0.7226 - val_loss: 0.2434 - val_acc: 0.9318\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 32s 601us/step - loss: 0.7871 - acc: 0.7237 - val_loss: 0.2412 - val_acc: 0.9320\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 33s 604us/step - loss: 0.7713 - acc: 0.7304 - val_loss: 0.2533 - val_acc: 0.9352\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 33s 604us/step - loss: 0.7576 - acc: 0.7355 - val_loss: 0.2291 - val_acc: 0.9408\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 33s 605us/step - loss: 0.7429 - acc: 0.7446 - val_loss: 0.2374 - val_acc: 0.9352\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 33s 604us/step - loss: 0.7271 - acc: 0.7468 - val_loss: 0.2264 - val_acc: 0.9378\n",
      "Num_LeNet-1-conv-128-nodes-1-dense-drop-20-epo-7.0-drop-1570289275\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               1384576   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,386,762\n",
      "Trainable params: 1,386,634\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 45s 841us/step - loss: 0.8280 - acc: 0.7314 - val_loss: 0.2386 - val_acc: 0.9317\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 45s 836us/step - loss: 0.6387 - acc: 0.8000 - val_loss: 0.2157 - val_acc: 0.9325\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 45s 836us/step - loss: 0.5876 - acc: 0.8169 - val_loss: 0.1957 - val_acc: 0.9408\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 45s 837us/step - loss: 0.5532 - acc: 0.8256 - val_loss: 0.1940 - val_acc: 0.9425\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 45s 838us/step - loss: 0.5299 - acc: 0.8349 - val_loss: 0.1774 - val_acc: 0.9473\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 45s 838us/step - loss: 0.5160 - acc: 0.8401 - val_loss: 0.1761 - val_acc: 0.9493\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 45s 840us/step - loss: 0.4978 - acc: 0.8444 - val_loss: 0.1696 - val_acc: 0.9492\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 45s 835us/step - loss: 0.4817 - acc: 0.8495 - val_loss: 0.1653 - val_acc: 0.9532\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 45s 836us/step - loss: 0.4724 - acc: 0.8518 - val_loss: 0.1637 - val_acc: 0.9523\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 45s 839us/step - loss: 0.4669 - acc: 0.8538 - val_loss: 0.1676 - val_acc: 0.9523\n",
      "Num_LeNet-1-conv-64-nodes-2-dense-drop-20-epo-7.0-drop-1570289729\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                692288    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 697,994\n",
      "Trainable params: 697,866\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 34s 624us/step - loss: 2.1832 - acc: 0.1691 - val_loss: 1.8222 - val_acc: 0.4403\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 33s 620us/step - loss: 2.0703 - acc: 0.2123 - val_loss: 1.6046 - val_acc: 0.4752\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 33s 620us/step - loss: 2.0441 - acc: 0.2222 - val_loss: 1.6005 - val_acc: 0.4620\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 33s 618us/step - loss: 2.0290 - acc: 0.2250 - val_loss: 1.5583 - val_acc: 0.4778\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 33s 618us/step - loss: 2.0264 - acc: 0.2230 - val_loss: 1.5222 - val_acc: 0.4693\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 33s 619us/step - loss: 2.0170 - acc: 0.2264 - val_loss: 1.5176 - val_acc: 0.4818\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 34s 620us/step - loss: 2.0133 - acc: 0.2280 - val_loss: 1.5071 - val_acc: 0.4932\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000/54000 [==============================] - 33s 618us/step - loss: 2.0039 - acc: 0.2300 - val_loss: 1.5235 - val_acc: 0.5092\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 33s 620us/step - loss: 2.0015 - acc: 0.2298 - val_loss: 1.5078 - val_acc: 0.5452\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 33s 620us/step - loss: 1.9905 - acc: 0.2374 - val_loss: 1.5142 - val_acc: 0.5408\n",
      "Num_LeNet-1-conv-128-nodes-2-dense-drop-20-epo-7.0-drop-1570290064\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               1384576   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,403,274\n",
      "Trainable params: 1,403,146\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 47s 861us/step - loss: 2.0844 - acc: 0.2362 - val_loss: 1.4886 - val_acc: 0.5277\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 46s 856us/step - loss: 1.8532 - acc: 0.3271 - val_loss: 1.3550 - val_acc: 0.5415\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 46s 856us/step - loss: 1.7949 - acc: 0.3425 - val_loss: 1.2980 - val_acc: 0.5600\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 46s 856us/step - loss: 1.7625 - acc: 0.3494 - val_loss: 1.2257 - val_acc: 0.5945\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 46s 857us/step - loss: 1.7396 - acc: 0.3586 - val_loss: 1.2119 - val_acc: 0.5995\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 46s 856us/step - loss: 1.7169 - acc: 0.3675 - val_loss: 1.1935 - val_acc: 0.6798\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 46s 857us/step - loss: 1.6774 - acc: 0.3825 - val_loss: 1.1067 - val_acc: 0.6978\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 46s 856us/step - loss: 1.6521 - acc: 0.3909 - val_loss: 1.0796 - val_acc: 0.7037\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 46s 854us/step - loss: 1.6392 - acc: 0.3976 - val_loss: 1.1018 - val_acc: 0.7023\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 46s 854us/step - loss: 1.6100 - acc: 0.4051 - val_loss: 1.1201 - val_acc: 0.6643\n"
     ]
    }
   ],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = f\"Num_LeNet-{conv_layer}-conv-{layer_size}-nodes-{dense_layer}-dense-{drop_rate*10}-drop-{epoch_time}-epo-{int(time.time())}\"\n",
    "            print(NAME)\n",
    "            tensorboard = TensorBoard(log_dir = 'logs/{}'.format(NAME))\n",
    "            \n",
    "            \n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=(28,28,1),padding='valid',activation='relu',kernel_initializer='uniform'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(64,(3,3),strides=(1,1),padding='valid',activation='relu',kernel_initializer='uniform'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "            \n",
    "            model.add(Flatten())\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation='relu'))\n",
    "                model.add(Dropout(0.7))\n",
    "                \n",
    "            model.add(Dense(10,activation='softmax'))\n",
    "            model.compile(optimizer=Adam(lr=0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "            model.summary()\n",
    "\n",
    "            # ————————————————\n",
    "            # 版权声明：本文为CSDN博主「wmy199216」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。\n",
    "            # 原文链接：https://blog.csdn.net/wmy199216/article/details/71171401\n",
    "\n",
    "            model.fit(x_train_mat, y_train_mat, epochs=epoch_time, validation_split=0.1, callbacks=[tensorboard])\n",
    "            model.save(NAME + \".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               102500    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 155,990\n",
      "Trainable params: 155,798\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 28s 519us/step - loss: 0.7842 - acc: 0.7494 - val_loss: 0.4873 - val_acc: 0.8507\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 27s 503us/step - loss: 0.4369 - acc: 0.8633 - val_loss: 0.3051 - val_acc: 0.9050\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 27s 506us/step - loss: 0.3123 - acc: 0.9032 - val_loss: 0.2186 - val_acc: 0.9348\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 27s 498us/step - loss: 0.2500 - acc: 0.9231 - val_loss: 0.1770 - val_acc: 0.9498\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 27s 498us/step - loss: 0.2113 - acc: 0.9343 - val_loss: 0.1646 - val_acc: 0.9523\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 27s 497us/step - loss: 0.1851 - acc: 0.9431 - val_loss: 0.1343 - val_acc: 0.9625\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 27s 497us/step - loss: 0.1675 - acc: 0.9483 - val_loss: 0.1306 - val_acc: 0.9610\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 27s 501us/step - loss: 0.1518 - acc: 0.9536 - val_loss: 0.1176 - val_acc: 0.9663\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 27s 496us/step - loss: 0.1411 - acc: 0.9566 - val_loss: 0.1192 - val_acc: 0.9673\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 27s 503us/step - loss: 0.1299 - acc: 0.9603 - val_loss: 0.1128 - val_acc: 0.9682\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(32,(5,5),strides=(1,1),input_shape=(28,28,1),padding='valid',activation='relu',kernel_initializer='uniform'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv2D(64,(5,5),strides=(1,1),padding='valid',activation='relu',kernel_initializer='uniform'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Flatten(input_shape=(4, 4, 64)))\n",
    "# model.add(Dense(100,activation='relu'))\n",
    "# model.add(Dense(10,activation='softmax'))\n",
    "# model.compile(optimizer=Adam(lr=0.0001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "# # ————————————————\n",
    "# # 版权声明：本文为CSDN博主「wmy199216」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。\n",
    "# # 原文链接：https://blog.csdn.net/wmy199216/article/details/71171401\n",
    "\n",
    "# model.fit(x_train_mat, y_train_mat, epochs=10, validation_split=0.1, callbacks=[tensorboard])\n",
    "# model.save('epic_num_LeNet.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "## test load code\n",
    "\n",
    "# IMG_SIZE = 256\n",
    "# index = 0\n",
    "\n",
    "# resize_img = cv2.resize(x_train_mat[index], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "# print(y_train_mat[index])\n",
    "# cv2.imshow('test', resize_img)\n",
    "\n",
    "# key_in = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "# if key_in == 27:    # esc\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
